{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb9816f-1558-4953-a84f-be4e5901691a",
   "metadata": {},
   "source": [
    "The below code is extracted from https://huggingface.co/learn/deep-rl-course/unit1/hands-on\n",
    "\n",
    "Dependencies required for Colab are not used here, since this notebook is designed to be run offline.\n",
    "Also, huggingface specific modules are not imported in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7419418-4319-472e-a14f-282bd516f852",
   "metadata": {},
   "source": [
    "# Import all modules required for this unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ba02f-aef9-46eb-bbef-0a0425098648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081803f8-672c-45df-9024-df201f73e3ca",
   "metadata": {},
   "source": [
    "## An example evaluation loop running a random policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557ba0c-be54-4157-ba0a-6367fce72c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# First, we create our environment called LunarLander-v2\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Then we reset this environment\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(20):\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(\"Action taken:\", action)\n",
    "\n",
    "    # Do this action in the environment and get\n",
    "    # next_state, reward, terminated, truncated and info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the game is terminated (in our case we land, crashed) or truncated (timeout)\n",
    "    if terminated or truncated:\n",
    "        # Reset the environment\n",
    "        print(\"Environment is reset\")\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915ae8f-36ea-4d08-9f39-334e3d2b5634",
   "metadata": {},
   "source": [
    "## Examining the observation space and action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659d46b-fb3e-475d-a997-1ffbbbea67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our environment with gym.make(\"<name_of_the_environment>\")\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env.reset()\n",
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space Shape\", env.observation_space.shape)\n",
    "print(\"Sample observation\", env.observation_space.sample())  # Get a random observation\n",
    "\n",
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample())  # Take a random action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5be075-bc8c-4374-a943-685752b810e0",
   "metadata": {},
   "source": [
    "### Importance of checking the observation space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799086d-2be6-433e-840f-1075333fe484",
   "metadata": {},
   "source": [
    "On the huggingface tutorial, it states that the last 2 observations are Booleans, however, sampling the observation space gave values between 0 and 1, instead of just a 0 or 1.\n",
    "Can you explain the reason for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ff9d3-9029-4898-b548-ece034d8c009",
   "metadata": {},
   "source": [
    "## Creating your first environment and defining your policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a62edd-bf31-49cf-8105-098e16878e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb243fb-501a-4c84-94c2-0c4365b00bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hypermeters for your policy\n",
    "model = PPO(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=env,\n",
    "    n_steps=1024,\n",
    "    batch_size=64,\n",
    "    n_epochs=4,\n",
    "    gamma=0.999,\n",
    "    gae_lambda=0.98,\n",
    "    ent_coef=0.01,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da780dfa-a7eb-451f-9f7a-0c3020c74724",
   "metadata": {},
   "source": [
    "## Train your policy with just a single line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2c590-d196-4727-9e79-527548b76425",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1000) #000\n",
    "\n",
    "# Save the model after training\n",
    "model_name = \"ppo-LunarLander-v2\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021597c-6ddf-4421-af14-331543e8fd32",
   "metadata": {},
   "source": [
    "## Evaluate your model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64040c-079d-45a0-a47c-591670615862",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b892d-7ddc-46ec-b46e-664db5d51f6d",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804dd8c7-a589-4647-bf3e-048c158cbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def show_gif(fname):\n",
    "    from IPython import display\n",
    "    with open(fname, 'rb') as fd:\n",
    "        b64 = base64.b64encode(fd.read()).decode('ascii')\n",
    "    return display.HTML(f'<img src=\"data:image/gif;base64,{b64}\" />')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9792804-84e5-4484-954e-103258ccdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "param_filename = 'LunarLander'\n",
    "\n",
    "render_env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "\n",
    "state, info = render_env.reset()\n",
    "img = render_env.render()\n",
    "images.append(Image.fromarray(img))\n",
    "\n",
    "while not terminated or truncated:\n",
    "    action = model.predict(state)\n",
    "    state, reward, terminated, truncated, info = render_env.step(action[0])\n",
    "    img = render_env.render()\n",
    "    images.append(Image.fromarray(img))\n",
    "\n",
    "# Save your gif\n",
    "images[0].save(f\"{param_filename}.gif\", save_all=True, append_images=images[1:],loop=0)\n",
    "\n",
    "show_gif(f\"{param_filename}.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c91ad-07ab-4f56-a16c-3efe504f4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
